{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression #Max entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Yelp reviews to be similar to movie reviews\n",
    "import unicodedata\n",
    "reviewpath = \"../Data/ExtraCredit/Yelp/all_reviews.txt\"\n",
    "\n",
    "old_neglines=[]\n",
    "old_poslines=[]\n",
    "#function to read all negative and positive lines into separate lists\n",
    "f = open(reviewpath, mode=\"r\",encoding='utf-8')\n",
    "lines = f.read() #switched from readlines() to read the entire review\n",
    "allrev =lines.split(\"]]]\") #split each review. will need to process other brackets\n",
    "allrev.pop() #removes the last item, which is empty\n",
    "#For each review, isolate the text and put into positive or negative list\n",
    "#depending on the associated rating. 1-3 stars = negative, and 4-5 stars = positive\n",
    "for i in range(len(allrev)):\n",
    "    currlines = allrev[i].splitlines()\n",
    "    #Remove empty first line from reviews:\n",
    "    if(i>0):\n",
    "        currlines = currlines[1:]\n",
    "    positive_review = False\n",
    "    rating = int(currlines[1][0])\n",
    "    if rating > 3:\n",
    "        positive_review = True\n",
    "    #Get review text: line 7 until end, minus 3 blank lines at the end\n",
    "    currlines = currlines[7:-3]\n",
    "    #print(currlines)\n",
    "    currlines = \" \".join(currlines)\n",
    "    #Remove weird symbols like \"\\xa0\":\n",
    "    currlines = unicodedata.normalize(\"NFKD\",currlines)\n",
    "    #Add spaces between punctuation and words. Extra spaces don't matter.\n",
    "    currlines = re.sub(r\"([^\\w\\s])\",r\" \\1 \", currlines)\n",
    "\n",
    "    if positive_review:\n",
    "        old_poslines.append(currlines)\n",
    "    else:\n",
    "        old_neglines.append(currlines)\n",
    "\n",
    "#print(len(old_neglines)+len(old_poslines)) #number of reviews: 10391\n",
    "#print(len(old_neglines)) #number of negative (1-3 star) reviews:1172+1358+1795 = 4325\n",
    "#print(old_neglines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing: lowercase and words only (remove punctuation, numbers)\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords minus negation\n",
    "stop_words = set(stopwords.words(\"english\"))-set([\"couldn't\",\"wouldn\",\"haven't\",\"haven\",\"aren\",\"aren't\",\"isn\",\"isn't\",\"ain\",\"wouldn't\",\"didn\",\"didn't\",\"doesn\",\"doesn't\",\"wasn't\",\"don\",\"don't\",\"couldn\",\"shouldn\",\"shouldn't\",\"hasn\",\"hasn't\",\"hadn\",\"hadn't\",\"not\",\"won\",\"won't\",])\n",
    "neg_words = \"never|nothing|nowhere|none|havent|hasnt|hadnt|cant|couldnt|shouldnt|wont|wouldnt|dont|doesnt|didnt|isnt|arent|aint|no$|not$\"\n",
    "\n",
    "def preprocess(listlines):\n",
    "    processed = []\n",
    "    for line in listlines:\n",
    "        #reviews appear to already be in lowercase, but ensure that's the case:\n",
    "        newline = line.lower()\n",
    "        newline = newline.split()\n",
    "        #remove stopwords\n",
    "        newline = [word for word in newline if not word in stop_words]\n",
    "        newline = ' '.join(newline)\n",
    "        #remove non-alphabet characters, keeping underscore.\n",
    "        newline = re.sub(r\"[^a-zA-z\\s_]\",'',newline) \n",
    "        #print(newline)\n",
    "        processed.append(newline)\n",
    "    return processed\n",
    "neglines = preprocess(old_neglines)\n",
    "poslines = preprocess(old_poslines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label each line with \"positive\" or \"negative\"\n",
    "def labellines(listlines, sentiment):\n",
    "    labeled = []\n",
    "    for line in listlines:\n",
    "        curr_line = []\n",
    "        curr_line.append(line)\n",
    "        curr_line.append(sentiment)\n",
    "        labeled.append(curr_line)\n",
    "    return labeled\n",
    "neglabeled=labellines(neglines,\"Negative\")\n",
    "poslabeled=labellines(poslines,\"Positive\")\n",
    "lines = neglabeled+poslabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                word sentiment\n",
      "0  ordered kung pao chicken  came pieces chicken ...  Negative\n",
      "1  food good service awful  placed order online w...  Negative\n",
      "2  seeking decent chinese take  delivery restaura...  Negative\n",
      "3  took  minutes food get   forgot spring roll  h...  Negative\n",
      "4  disappointed entre  e purchase  vegetables har...  Negative\n",
      "5  not vietnamese restaurant  friend ordered  dif...  Negative\n",
      "6  place awesome  jacked prices   dollars  spring...  Negative\n",
      "7   lived champaign  years   want  love pekara su...  Negative\n",
      "8  travelling stopped breakfast  organic eggs ome...  Negative\n",
      "9  worst crepe        european cafe don  know mak...  Negative\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(lines, columns=[\"word\",\"sentiment\"])\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"sentiment\"]\n",
    "data = df.drop(columns=[\"sentiment\"])\n",
    "X = data[\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From demo:\n",
    "# Define a function to take as input training and testing vectors and labels\n",
    "# Allow this to be extensible to let multiple classifiers be used here\n",
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # if you get a zero-devision warning message, you can supress it by setting zero_division=0\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 for Naive_Bayes:\t\t 0.7692706881026681\n",
      "Average Precision for Naive_Bayes:\t 0.8027028271589446\n",
      "Average Recall for Naive_Bayes:\t 0.7619383632441006\n",
      "Average Accuracy for Naive_Bayes:\t 0.7877950410192952\n",
      "Average F1 for Decision_Tree:\t\t 0.7244753466219658\n",
      "Average Precision for Decision_Tree:\t 0.72359220613212\n",
      "Average Recall for Decision_Tree:\t 0.728510063287598\n",
      "Average Accuracy for Decision_Tree:\t 0.728804938333331\n",
      "Average F1 for Max_Entropy:\t\t 0.8114827694225596\n",
      "Average Precision for Max_Entropy:\t 0.8097807062380287\n",
      "Average Recall for Max_Entropy:\t 0.816564657087943\n",
      "Average Accuracy for Max_Entropy:\t 0.8144547820197483\n"
     ]
    }
   ],
   "source": [
    "# Construct the classifiers at hand prior to folding the data through them\n",
    "names = ['Naive_Bayes', 'Decision_Tree','Max_Entropy']#,'Support_Vector_Machines']\n",
    "classifiers = [MultinomialNB(), \n",
    "              DecisionTreeClassifier(random_state=0, criterion='gini'), LogisticRegression(random_state=0,max_iter=1000)]#, SVC(kernel='linear')]\n",
    "# names = ['Max_Entropy']\n",
    "# classifiers = [LogisticRegression(random_state=0,max_iter=1000)]\n",
    "# Try different classifiers: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "for name, clf in zip(names, classifiers):\n",
    "\n",
    "    #print('Now classifying', name)\n",
    "\n",
    "    # Fold the data 5 times\n",
    "    kf = KFold(n_splits = 5, shuffle=True, random_state=0) #changed to not need shuffle\n",
    "    foldCounter = 0\n",
    "    aList, bList, cList, dList = list(), list(), list(), list()\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        #vectorize here:\n",
    "        vectorizer = CountVectorizer()\n",
    "        X_train_vect = vectorizer.fit_transform(X_train).toarray()\n",
    "        X_test_vect = vectorizer.transform(X_test).toarray()\n",
    "        f1, precision, recall, accuracy = buildClassifiers(clf, X_train_vect, X_test_vect, y_train, y_test)\n",
    "        aList.append(f1)\n",
    "        bList.append(precision)\n",
    "        cList.append(recall)\n",
    "        dList.append(accuracy)\n",
    "    print(\"Average F1 for {}:\\t\\t\".format(name), np.mean(aList))\n",
    "    print(\"Average Precision for {}:\\t\".format(name), np.mean(bList))\n",
    "    print(\"Average Recall for {}:\\t\".format(name), np.mean(cList))\n",
    "    print(\"Average Accuracy for {}:\\t\".format(name), np.mean(dList))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
